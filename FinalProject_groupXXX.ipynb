{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert title here\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Zixian Cai\n",
    "- Richard Masser-Frye\n",
    "- Vinuthna Hasthi\n",
    "- Pranav Nair\n",
    "- Jesus Tello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Broadly, recipes are sets of instructions for the purpose of preparing specific dishes. They generally include some information about the dish, the ingredients used in making the dish, and how to assemble or process those ingredients. In particular, baked goods are dishes (such as cookies, cakes, etc) that contain flour as a primary ingredient and involve combining ingredients to make a batter which is placed into an oven to bake. The consistency of the baked good generally depends on the proportions of flour, egg, sugar, butter, and baking powder used in the batter, and on how long and at what temperature it is baked.\n",
    "\n",
    "Recipe datasets have previously been used in machine learning research. Often, the research is not particularly focused on recipes, but uses them for their advantageous qualities (most recipes share a similar structure, they can be easily scraped from websites, they can't be copyrighted, etc). For example, a 2017 paper by Yang et al.<a name=\"yang\"></a>[<sup>[1]</sup>](#yangnote) used machine learning to analyze \"reference expressions\" (phrases that refer to previously mentioned objects in a text) and employed instructions from recipes as an example of this. Other published works are more explicitly food-focused; Herranz et al.<a name=\"herranz\"></a>[<sup>[2]</sup>](#herranznote) provides an overview of techniques that can be applied to recipes, ingredient lists, and even images of food. The paper associated with the RecipeNLG dataset by Bien et al.<a name=\"recipenlg\"></a>[<sup>[3]</sup>](#recipenlgnote) also provides an overview of previous efforts in machine learning on recipes, including the two aforementioned papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem at hand is the categorization of baked-goods recipes based on their ingredients. Though they are not explicitly numerical, these attributes have aspects that can be abstracted into numbers; specifically, the quantities of each ingredient in grams. Each recipe can thus be expressed as a vector, and clustering techniques (such as GMM or hierarchical clustering) can be attempted to the dataset to sort the recipes into groups. We can also use high-dimensional data visualization techniques like PCA or manifold learning to get a sense of the overall shape of the dataset. Finally, we can measure the success of the clustering by comparing the predicted labels to the true labels found in the original dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We used a dataset called RecipeNLG created by researchers at Poznan University of Technology.<a name=\"recipenlg2\"></a>[<sup>[3]</sup>](#recipenlgnote)\n",
    "\n",
    "- Links: [RecipeNLG official website](https://recipenlg.cs.put.poznan.pl/), [RecipeNLG Kaggle page](https://www.kaggle.com/datasets/paultimothymooney/recipenlg)\n",
    "- RecipeNLG contains 2,231,142 recipes in all, but for our project we filtered it down to 235,762 recipes that had \"cake\", \"cookie\" or \"muffin\" in the title. After processing, it was further filtered down to 145,087 data points.\n",
    "- Post-processing, an observation consists of quantities of each of the following ingredients, in grams:\n",
    "    - egg\n",
    "    - flour\n",
    "    - sugar\n",
    "    - butter\n",
    "    - vanilla extract\n",
    "    - milk\n",
    "    - evaporated milk\n",
    "    - condensed milk\n",
    "    - shortening\n",
    "    - powdered sugar\n",
    "    - cornmeal\n",
    "    - baking soda\n",
    "    - baking powder\n",
    "    - oats\n",
    "- Whether a particular datapoint is from a cake, cookie, or muffin recipe is stored in a column called 'category', and is treated as a ground truth observation (i.e. it is not used for unsupervised tasks)\n",
    "\n",
    "The initial filtering of the data for baked-goods recipes was done in [filter_recipes.ipynb](https://github.com/richmass1/group_template/blob/main/filter_recipes.ipynb), by selecting recipes that had in their titles \"cake\", \"cookie\", or \"muffin\". Converting the recipes into data points was done in [process_recipes.ipynb](https://github.com/richmass1/group_template/blob/main/process_recipes.ipynb), by searching each ingredient string (for example, `'1/2 c. sugar'`) for an ingredient name, then extracting the number and unit, converting the number to a float, then converting the unit to grams. \n",
    "\n",
    "After processing, the data was further filtered by removing data points that had no flour, data points with invalid values and datapoints with values that seemed overly large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Our strategy was to try a number of ML algorithms on the dataset, and see what did the best with our particular dataset. An early idea was to first reduce dimensionality, then use GMM to cluster the data points, and see whether GMM could accurately separate the recipe into their true categories. We also decided to try alternative clustering techniques like hierarchical clustering and spectral clustering. Finally, we tried PCA, UMAP, and t-SNE as data visualization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For clustering techniques like GMM and hierarchical clustering, we initially proposed using Bayesian information criterion (BIC) to evaluate the clustering itself, and adjusted Rand index (ARI) to evaluate how well it assigned data points. However, it turned out that the data was not conducive to simple clustering, rendering ARI unnecessary. \n",
    "\n",
    "For dimensionality reduction algorithms (PCA, t-SNE, UMAP) we used a more supervised approach. For all 3 techniques, we used silhouette scores with true labels to gauge how well it placed recipes of the same type near each other. For PCA and UMAP, we trained a k-nearest neighbors (kNN) classifier on the embedded d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"yangnote\"></a>1.[^](#yang): Zichao Yang, Phil Blunsom, Chris Dyer, and Wang Ling. (9 Aug 2017) Reference-Aware Language Models. https://arxiv.org/pdf/1611.01628.pdf<br> \n",
    "\n",
    "<a name=\"herranznote\"></a>2.[^](#herranz): Luis Herranz, Weiqing Min and Shuqiang Jiang. (22 Jan 2018) Food recognition and recipe analysis: integrating visual content, context and external knowledge. https://arxiv.org/pdf/1801.07239.pdf<br> \n",
    "\n",
    "<a name=\"recipenlgnote\"></a>3.[^](#recipenlg), [^](#recipenlg2): Michał Bień, Michał Gilski, Martyna Maciejewska, Wojciech Taisner, Dawid Wisniewski, and Agnieszka Lawrynowicz. (Dec 2020) RecipeNLG: A Cooking Recipes Dataset for Semi-Structured Text Generation. https://aclanthology.org/2020.inlg-1.4/<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
